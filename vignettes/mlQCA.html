<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>mlQCA</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">mlQCA</h1>



<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlQCA)</span></code></pre></div>
<div id="overall-workflow" class="section level2">
<h2>1. Overall Workflow</h2>
<p>The overall workflow of the package is intentionally straight-forward
(we assume you have pre-processed your data but have not calibrated it
yet):<br />
1. <strong>Build an xgboost model</strong> (classification based on your
outcome label)<br />
2. <strong>Estimate feature importance</strong> (based on the xgboost
model)<br />
3. <strong>Extract cutoffs</strong> (used by the xgboost model)<br />
4. <strong>Calibrate data</strong> (with the cutoffs)<br />
5. <strong>Estimate QCA metrics</strong> (using the calibrated
data)<br />
6. <strong>Form feature-ranking table</strong> (by tallying feature
importance and necessity metrics)<br />
7. <strong>Iterative QCA</strong> (by choosing k features from a given n
feature vector)</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="do">## 1. Build an xgboost model</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>xgb <span class="ot">&lt;-</span> <span class="fu">buildXGboost</span>(voteData, <span class="st">&quot;vote&quot;</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="do">## 2. estimate feature importance</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>fMetricModel <span class="ot">&lt;-</span> <span class="fu">getFeatureImp</span>(xgb, voteData, <span class="st">&quot;vote&quot;</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="do">## 3. Extract cutoffs</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>cutDf <span class="ot">&lt;-</span> <span class="fu">getXGboostCut</span>(xgb, <span class="at">full =</span> F)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="do">## 4. Calibrate data</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>voteDataCalibrated <span class="ot">&lt;-</span> <span class="fu">reCalibrateXGCut</span>(<span class="at">data =</span> voteData, <span class="at">cutoffs =</span> cutDf, <span class="at">outcome =</span> <span class="st">&quot;vote&quot;</span>, <span class="at">na.rm =</span> F)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="do">## 5. Estimate QCA metrics</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>fMetricQCA <span class="ot">&lt;-</span> <span class="fu">getQCAMetric</span>(voteDataCalibrated, <span class="st">&quot;vote&quot;</span>)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="do">## 6. Form feature-ranking table</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>fRankTable <span class="ot">&lt;-</span> <span class="fu">joinMetrics</span>(fMetricModel, fMetricQCA)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="do">## 7. Iterative QCA</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>selectFeatures <span class="ot">&lt;-</span> <span class="fu">head</span>(fMetricModel<span class="sc">$</span>feature, <span class="dv">10</span>)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>Res <span class="ot">&lt;-</span> <span class="fu">iterQCA</span>(<span class="at">features =</span> selectFeatures, <span class="at">k=</span><span class="dv">4</span>, <span class="at">dataCali =</span> voteDataCalibrated, <span class="at">outcome =</span> <span class="st">&quot;vote&quot;</span>, <span class="at">incl.cut =</span> <span class="fl">0.8</span>)</span></code></pre></div>
</div>
<div id="detailed-steps" class="section level2">
<h2>2. Detailed Steps</h2>
<div id="build-an-xgboost-model" class="section level3">
<h3>2.1 Build an xgboost model</h3>
<p>We assume you have pre-processed your data (including data cleaning,
renaming, filtering etc.), and we start by building an xgboost model.
Specifically, we build a tree ensemble classification model to classify
each observation into one of your outcome category.</p>
<p>In our example data <code>voteData</code>, our outcome label is
<code>&quot;vote&quot;</code>, indicating whether the interviewee voted or not.
Each row is a interviewee, and the features are various aspects about
the interviewee (e.g. education level, parent education level, etc.).
Refer to the <code>codebook</code> for the feature names.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(voteData) <span class="co"># 427 interviewees; 77 features, including &quot;vote&quot;</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 427  77</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(voteData<span class="sc">$</span>vote) <span class="co"># 319 voted; 108 did not vote;</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   0   1 </span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 108 319</span></span></code></pre></div>
<p>We then build an xgboost model to predict the <code>&quot;vote&quot;</code>
outcome. Under the hood, we built the model using the <code>caret</code>
and <code>xgboost</code> packages. To see details of the default
parameters used, call <code>?buildXGboost</code>.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="do">## this can take a few minutes</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">201</span>) <span class="do">## ensure reproducibility</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>xgb <span class="ot">&lt;-</span> <span class="fu">buildXGboost</span>(voteData, <span class="st">&quot;vote&quot;</span>)</span></code></pre></div>
<p>We can estimate the accuracy of the model to get an idea of how well
it differentiates the voters and the non-voters.Note that our goal here
is not to predict new data, but rather to understand the data at hand.
The accuracy, even modest as a general classification model, may be good
enough to show some success in using the given features to tell apart
the voters and non-voters.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">getAccXGboost</span>(xgb, voteData, <span class="st">&quot;vote&quot;</span>) </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 1</span></span></code></pre></div>
</div>
<div id="estimate-feature-importance" class="section level3">
<h3>2.2 Estimate feature importance</h3>
<p>We next use the built xgboost model to estimate the relative
importance of each feature in differentiating the voters from the
non-voters. More specifically, we look at four metrics: three extracted
direclty from the xgboost tree ensemble (gain, cover, frequency) and one
additional calculated measure (shapley value). Briefly, the meaning of
the four metrics are:</p>
<ul>
<li>Gain: improvement in accuracy brought by the feature to the branches
it is on</li>
<li>Cover: relative quantity of observations concerned by a feature</li>
<li>Frequency: the number of times a feature is used in all generated
trees</li>
<li>SHAP value (average): the average contribution of the feature to the
prediction of the model</li>
</ul>
<p>Detailed explanation of these measures, particularly Shapley values,
is out of the scope here, but there are many sources online that provide
great explanations and are easily searchable.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>fMetricModel <span class="ot">&lt;-</span> <span class="fu">getFeatureImp</span>(xgb, voteData, <span class="st">&quot;vote&quot;</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(fMetricModel)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   feature       Gain      Cover  Frequency      shap</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1  P_V530 0.03760118 0.04533344 0.01482702 0.3540378</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2    V648 0.02953969 0.03034436 0.01565074 0.3267870</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3  P_V195 0.04124526 0.04613385 0.05271829 0.3125727</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4    V207 0.03860001 0.04709416 0.04448105 0.2888913</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5    V191 0.01999109 0.02772152 0.01317957 0.2819319</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6    V204 0.03887744 0.04359945 0.04530478 0.2708880</span></span></code></pre></div>
</div>
<div id="extract-cutoffs" class="section level3">
<h3>2.3 Extract Cutoffs</h3>
<p>Since xgboost treen ensemble are a collection of individual tree
structures, we can extract and summarize the cutoffs used across them
and leverage on these cutoffs to calibrate our data. The default
behavior is to look at each feature’s cutoff across all trees and choose
the most frequently used one. Admittedly, these might not be the most
appropriate cutoffs depending on the contexts, and we showed that these
cutoffs, among all possible cutoffs, would produce QCA solutions that
are among top 10%. Still, we enourage the users to take these for
guidance and leverage on prior/domain knowledge to evaluate the their
relavance and appropriateness, and modify them accordingly.</p>
<p>Another potential catch of this approach is “missing features”. When
constructing model, there is certain built-in randomness (in selecting
features for each tree), and consequently some features (usually the
less informative ones) may not be used. This is normally okay, as the
“missing feautres” are very likely to be uninformative and thus least
useful for downstream QCA analysis. However, if certain features are
still desired, we can manually add them into the cutoff table and set a
cutoff for them. Alternatively, we can also set a different seed and
retrain the xgboost model to see if the features will be selected.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>cutDf <span class="ot">&lt;-</span> <span class="fu">getXGboostCut</span>(xgb, <span class="at">full =</span> F)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(cutDf)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 x 2</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   feature cutoff</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;    &lt;dbl&gt;</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 P_V136     3.5</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 P_V168     2.5</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 P_V185     0.5</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 P_V195    52.5</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 P_V242     2.5</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 P_V243     3.5</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="fu">nrow</span>(cutDf) <span class="co"># 72 of the 76 features selected; 4 &quot;missing&quot; features</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 72</span></span></code></pre></div>
</div>
<div id="calibrate-data" class="section level3">
<h3>2.4 Calibrate data</h3>
<p>When building the xgboost model, we do not require nor enourage the
input data to be calibrated. This ensures maximal details/information
that can be instrumental for classification. However, to proceed with
downstream QCA tasks, we have to calibrate the data. Since we extracted
the cutoffs above, we can use them directly to calibrate. Note that the
current version only support crisp calibration, and fuzzy set
calibration will be supported in future versions.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="do">## before calibration</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">unique</span>(voteData<span class="sc">$</span>V188)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 16 11 10 14  5 18  8  7  6  4 25  3  0  2 15 30 13 12 27 20  9 22 24  1 35</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [26] 28 17 23</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="do">## calibrate</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>voteDataCalibrated <span class="ot">&lt;-</span> <span class="fu">reCalibrateXGCut</span>(<span class="at">data =</span> voteData, <span class="at">cutoffs =</span> cutDf, <span class="at">outcome =</span> <span class="st">&quot;vote&quot;</span>, <span class="at">na.rm =</span> F)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="do">## after calibration</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="fu">unique</span>(voteDataCalibrated<span class="sc">$</span>V188)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 1 0</span></span></code></pre></div>
</div>
<div id="estimate-qca-metrics" class="section level3">
<h3>2.5 Estimate QCA metrics</h3>
<p>Now that we have the (re)calibrated data, we can perform a
per-feature QCA test to get an idea of some basic QCA metrics of each
feature.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>fMetricQCA <span class="ot">&lt;-</span> <span class="fu">getQCAMetric</span>(voteDataCalibrated, <span class="st">&quot;vote&quot;</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(fMetricQCA)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        Cons.Nec Cov.Nec   RoN feature</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; P_V136    0.574   0.769 0.775  P_V136</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; P_V168    0.473   0.737 0.804  P_V168</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; P_V185    0.429   0.721 0.817  P_V185</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; P_V195    0.411   0.780 0.875  P_V195</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; P_V242    0.696   0.768 0.673  P_V242</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; P_V243    0.473   0.702 0.768  P_V243</span></span></code></pre></div>
</div>
<div id="form-feature-ranking-table" class="section level3">
<h3>2.6 Form feature-ranking table</h3>
<p>We have constructed per-feature metrics from both the xgboost model
and per-feature QCA, and we can combine them to get a single feature
importance table and save for later reference. Note that the final
ranking <code>fRank</code> is still based on the “shap” value, which
best captures the learning from the xgboost model.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>fRankTable <span class="ot">&lt;-</span> <span class="fu">joinMetrics</span>(fMetricModel, fMetricQCA)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(fRankTable)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   feature       Gain      Cover  Frequency      shap Cons.Nec Cov.Nec   RoN</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1  P_V530 0.03760118 0.04533344 0.01482702 0.3540378   0.0846  0.4737 0.925</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2    V648 0.02953969 0.03034436 0.01565074 0.3267870   0.7490  0.8100 0.702</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3  P_V195 0.04124526 0.04613385 0.05271829 0.3125727   0.4110  0.7800 0.875</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4    V207 0.03860001 0.04709416 0.04448105 0.2888913   0.7590  0.7830 0.638</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5    V191 0.01999109 0.02772152 0.01317957 0.2819319   0.2100  0.8590 0.969</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6    V204 0.03887744 0.04359945 0.04530478 0.2708880   0.6900  0.7970 0.729</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   fRank</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1     1</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2     2</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3     3</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4     4</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5     5</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6     6</span></span></code></pre></div>
</div>
<div id="iterative-qca" class="section level3">
<h3>2.7 Iterative QCA</h3>
<p>The feature ranking table is great for reference, and we have shown
that the top features on average provide much better QCA solutions than
the bottom ones. However, even among the top 10, we normally want to
choose 3 to 4 features to analyze using QCA. This presents a problem as
we do not know which 3 or 4 out of 10 features might give us the best
solution. To address this, we perform iterative QCA sufficiency tests
and summarize the results.</p>
<p>Specifically, as an example, let’s choose the top 10 features from
the feature ranking table as our “pool” of features. We then iteratively
choose 4 out of the 10 features to do QCA analysis, exhaustively
examining all combinations of “10-choose-4”. The resulting solutions
include the particular combination of 4 features, the corresponding
solution and the metric scores for that solution. In addition, the
results are also ranked based on the coverage as a guidance. Users are
then encouraged to examine this table to determine the best features to
use. Note that the features to choose from are manually determined by
the users, and they need not to be the top features form the ranking
table.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>selectFeatures <span class="ot">&lt;-</span> <span class="fu">head</span>(fMetricModel<span class="sc">$</span>feature, <span class="dv">10</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="do">## this can take a few minutes</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>Res <span class="ot">&lt;-</span> <span class="fu">iterQCA</span>(<span class="at">features =</span> selectFeatures, <span class="at">k=</span><span class="dv">4</span>, <span class="at">dataCali =</span> voteDataCalibrated, <span class="at">outcome =</span> <span class="st">&quot;vote&quot;</span>, <span class="at">incl.cut =</span> <span class="fl">0.8</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Res)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                    features</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1     P_V530,V648,V207,V141</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2   P_V530,V648,P_V195,V207</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 P_V530,P_V195,V141,P_V392</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4    P_V530,V204,P_V59,V141</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5   P_V530,V648,P_V195,V191</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 P_V530,P_V195,P_V59,P_V44</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                                                    path     inclS       PRI</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 ~P_V530*V648*V207+~P_V530*V648*V141+~P_V530*V207*V141 0.8343949 0.8343949</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2                     ~P_V530*V648+~P_V530*~P_V195*V207 0.8333333 0.8333333</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3              ~P_V530*~P_V195*V141+~P_V530*V141*P_V392 0.8349835 0.8349835</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4                 ~P_V530*V204*V141+~P_V530*~P_V59*V141 0.8466899 0.8466899</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5                     ~P_V530*V648+~P_V530*~P_V195*V191 0.8380282 0.8380282</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6                          ~P_V530*~P_V59+~P_V530*P_V44 0.8292683 0.8292683</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       convS rank</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 0.8213166    1</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 0.8150470    2</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 0.7931034    3</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 0.7617555    4</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 0.7460815    5</span></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 0.7460815    6</span></span></code></pre></div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
